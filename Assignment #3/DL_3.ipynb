{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_3_9352.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPYNl4DNkrlhFN8Xk2DOplS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **RADIAL BASIS FUNCTION ANN IMPLEMENTATION**\n","**Dataset:** Airfoil Self-Noise Data Set (UCI)\n","--\n","\n","***Spyrakis Angelos***, *ECE AUTh (9352)*\n","\n","---\n","Table of Contents:\n","\n","**1. K-Nearest-Neighbors**\n","\n","**2. Radial Basis Function ANN**\n",">\n",">2.1. Fine-tuning RBF model using Keras tuner\n",">\n",">2.2. Fine-tuned RBF model\n",">\n","\n","**3. RBF ANN With Perceptron Layer**\n",">\n",">3.1. Fine-tuning RBF+P model using Keras tuner\n",">\n",">3.2. Fine-tuned RBF+P model\n",">\n","\n","---\n","Execute the following cells to download the data set and the keras tuner."],"metadata":{"id":"KuDh4eH0x86v"}},{"cell_type":"code","source":["!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat"],"metadata":{"id":"JoZJ0TJZPNVK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install -q -U keras-tuner"],"metadata":{"id":"OY7zDmLIBztM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.K-Nearest-Neighbors"],"metadata":{"id":"fAS_U9w5v3G3"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor, NearestCentroid\n","\n","\n","def load_airfoil_dataset():\n","    \"\"\"Load the Airfoil Self-Noise dataset from the current directory\n","    \"\"\"\n","    data = pd.read_csv('./airfoil_self_noise.dat', sep='\\t', header=None)\n","\n","    X = data.loc[:,0:4]\n","    y = data.loc[:,5]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)\n","\n","    # Feature normalization\n","    mean = X_train.mean(axis=0)\n","    X_train -= mean\n","    X_test -= mean\n","\n","    std = X_train.std(axis=0)\n","    X_train /= std\n","    X_test /= std\n","\n","    return X_train, X_test, y_train, y_test\n","\n","\n","def knn(k, X_train, X_test, y_train, y_test):\n","    \"\"\"K-nearest neighbor implementation\n","    \"\"\"\n","    print('Executing KNN with k = %d...\\n' % (k))\n","    start_time = time.time()\n","\n","    knn_regressor = KNeighborsRegressor(n_neighbors=k, weights='uniform', algorithm='auto')\n","    knn_regressor.fit(X_train, y_train)\n","\n","    y_predicted = knn_regressor.predict(X_test)\n","    elapsed_time = time.time() - start_time\n","\n","    rmse = mean_squared_error(y_test, y_predicted, squared=False)\n","    r2 = r2_score(y_test, y_predicted)\n","    \n","    print('KNN RMSE = %f' % rmse)\n","    print('KNN R2 = %f' % r2)\n","    print('Elapsed time: %.2f seconds.\\n' % elapsed_time)\n","\n","\n","def main():\n","    X_train, X_test, y_train, y_test = load_airfoil_dataset()\n","\n","    #KNN implementation\n","    knn(2, X_train, X_test, y_train, y_test)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"DXTdSIVWv1Oz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2.Radial Basis Function ANN"],"metadata":{"id":"OOQ3kWtdwCR7"}},{"cell_type":"markdown","source":["##2.1. Fine-tuning RBF model using Keras tuner"],"metadata":{"id":"uAphcfOOqJI6"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras_tuner as kt\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.models import Sequential\n","from keras import backend as K\n","from tensorflow.keras.layers import Layer\n","from keras.initializers import Initializer, Constant \n","from sklearn.cluster import KMeans\n","\n","\n","def load_airfoil_dataset():\n","    \"\"\"Load the Airfoil Self-Noise dataset from the current directory\n","    \"\"\"\n","    data = pd.read_csv('./airfoil_self_noise.dat', sep='\\t', header=None)\n","\n","    X = data.loc[:,0:4]\n","    y = data.loc[:,5]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)\n","\n","    # Feature normalization\n","    mean = X_train.mean(axis=0)\n","    X_train -= mean\n","    X_test -= mean\n","\n","    std = X_train.std(axis=0)\n","    X_train /= std\n","    X_test /= std\n","\n","    return X_train, X_test, y_train, y_test\n","\n","\n","class RBFLayer(Layer):\n","\n","    def __init__(self, output_dim, centers_initializer, betas_trainable=False, **kwargs):\n","        self.output_dim = output_dim    # number of neurons in hidden layer\n","        self.init_betas = np.ones(self.output_dim)\n","        self.betas_trainable = betas_trainable\n","        self.centers_initializer = centers_initializer\n","        super(RBFLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.centers = self.add_weight(name='centers',\n","                                       shape=(self.output_dim, input_shape[1]),\n","                                       initializer=self.centers_initializer,\n","                                       trainable=False)\n","        \n","        if self.betas_trainable==True:\n","            self.betas = self.add_weight(name='betas',\n","                                        shape=(self.output_dim,),\n","                                        initializer=Constant(value=self.init_betas),\n","                                        trainable=True)\n","        else:\n","            # find max distance between any two centroids\n","            dmax = 0\n","            for i in range(0, self.output_dim):\n","                for j in range(0, self.output_dim):\n","                    if tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i]-self.centers[j]))) > dmax:\n","                        dmax = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i]-self.centers[j])))\n","            \n","            beta = self.output_dim/(dmax**2)\n","            self.betas = self.init_betas*beta\n","\n","        super(RBFLayer, self).build(input_shape)\n","\n","    def call(self, x):\n","        C = self.centers[np.newaxis, :, :]\n","        X = x[:, np.newaxis, :]\n","\n","        diffnorm = K.sum((C-X)**2, axis=-1)\n","        ret = K.exp( - self.betas * diffnorm)  # this is the RB function\n","        return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_dim)\n","\n","\n","class KMeansInit(Initializer):\n","\n","    def __init__(self, X, max_iter=400):\n","        self.X = X\n","        self.max_iter = max_iter\n","\n","    def __call__(self, shape, dtype=None):\n","        assert shape[1] == self.X.shape[1]\n","\n","        n_centers = shape[0]\n","        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0)\n","        km.fit(self.X)\n","        return km.cluster_centers_\n","\n","\n","def RMSE(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","\n","def MSE(y_true, y_pred):\n","    return K.mean(K.square(y_pred - y_true))\n","\n","\n","def R_squared(y_true, y_pred):\n","    SS_res =  K.sum(K.square(y_true - y_pred))\n","    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n","    return ( 1 - SS_res/(SS_tot + K.epsilon()) ) # K.epsilon()=1E-8 avoids division with zero\n","\n","\n","class myRBFModel(kt.HyperModel):\n","\n","    def __init__(self, X_train):\n","        self.X_train = X_train\n","    \n","    def build(self, hp):\n","        model = Sequential()\n","\n","        hp_rbf_neurons = hp.Choice('rbf_neurons', values=[int(0.1*self.X_train.shape[0]), int(0.2*self.X_train.shape[0]), \n","                                    int(0.3*self.X_train.shape[0]), int(0.5*self.X_train.shape[0]), int(0.9*self.X_train.shape[0])])\n","        model.add(RBFLayer(hp_rbf_neurons, centers_initializer=KMeansInit(self.X_train), input_shape=(5,)))\n","\n","        model.add(Dense(1))\n","\n","        hp_lr = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001])\n","        opt = tf.keras.optimizers.SGD(learning_rate=hp_lr)\n","\n","        model.compile(loss = MSE, metrics=[RMSE, R_squared], optimizer=opt)\n","\n","        return model\n","\n","\n","def main():\n","    X_train, X_test, y_train, y_test = load_airfoil_dataset()\n","    \n","    rbf_model = myRBFModel(X_train = X_train)\n","\n","    # Set up tuner\n","    tuner = kt.RandomSearch(rbf_model, objective=kt.Objective('val_R_squared', direction='max'), max_trials=15, executions_per_trial=5, overwrite=True)\n","    tuner.search(X_train, y_train, epochs=100, validation_split=0.2, batch_size=15)\n","\n","    # Get the optimal hyperparameters\n","    best_hps=tuner.get_best_hyperparameters(1)[0]\n","\n","    print(f\"\"\"\n","    The hyperparameter search is complete. The optimal number of neurons for the RBF layer is {best_hps.get('rbf_neurons')}, \n","    and the optimal learning rate is {best_hps.get('learning_rate')}.\n","    \"\"\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"it3tNpgBu2My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"D6yl13RHyuB4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2.2. Fine-tuned RBF model"],"metadata":{"id":"oEJzsWrmCw1h"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUc1sFI2en1f"},"outputs":[],"source":["import numpy as np\n","import time\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.models import Sequential\n","from keras import backend as K\n","from tensorflow.keras.layers import Layer\n","from keras.initializers import Initializer, Constant \n","from sklearn.cluster import KMeans\n","\n","\n","def load_airfoil_dataset():\n","    \"\"\"Load the Airfoil Self-Noise dataset from the current directory\n","    \"\"\"\n","    data = pd.read_csv('./airfoil_self_noise.dat', sep='\\t', header=None)\n","\n","    X = data.loc[:,0:4]\n","    y = data.loc[:,5]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)\n","\n","    # Feature normalization\n","    mean = X_train.mean(axis=0)\n","    X_train -= mean\n","    X_test -= mean\n","\n","    std = X_train.std(axis=0)\n","    X_train /= std\n","    X_test /= std\n","\n","    return X_train, X_test, y_train, y_test\n","\n","\n","class RBFLayer(Layer):\n","\n","    def __init__(self, output_dim, centers_initializer, betas_trainable=False, **kwargs):\n","        self.output_dim = output_dim    # number of neurons in hidden layer\n","        self.init_betas = np.ones(self.output_dim)\n","        self.betas_trainable = betas_trainable\n","        self.centers_initializer = centers_initializer\n","        super(RBFLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.centers = self.add_weight(name='centers',\n","                                       shape=(self.output_dim, input_shape[1]),\n","                                       initializer=self.centers_initializer,\n","                                       trainable=False)\n","        \n","        if self.betas_trainable==True:\n","            self.betas = self.add_weight(name='betas',\n","                                        shape=(self.output_dim,),\n","                                        initializer=Constant(value=self.init_betas),\n","                                        trainable=True)\n","        else:\n","            # find max distance between any two centroids\n","            dmax = 0\n","            for i in range(0, self.output_dim):\n","                for j in range(0, self.output_dim):\n","                    if tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i]-self.centers[j]))) > dmax:\n","                        dmax = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i]-self.centers[j])))\n","            \n","            beta = self.output_dim/(dmax**2)\n","            self.betas = self.init_betas*beta\n","\n","        super(RBFLayer, self).build(input_shape)\n","\n","    def call(self, x):\n","        C = self.centers[np.newaxis, :, :]\n","        X = x[:, np.newaxis, :]\n","\n","        diffnorm = K.sum((C-X)**2, axis=-1)\n","        ret = K.exp( - self.betas * diffnorm)  # this is the RB function\n","        return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_dim)\n","\n","\n","class KMeansInit(Initializer):\n","\n","    def __init__(self, X, max_iter=400):\n","        self.X = X\n","        self.max_iter = max_iter\n","\n","    def __call__(self, shape, dtype=None):\n","        assert shape[1] == self.X.shape[1]\n","\n","        n_centers = shape[0]\n","        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0)\n","        km.fit(self.X)\n","        return km.cluster_centers_\n","\n","\n","def RMSE(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","\n","def MSE(y_true, y_pred):\n","    return K.mean(K.square(y_pred - y_true))\n","\n","\n","def R_squared(y_true, y_pred):\n","    SS_res =  K.sum(K.square(y_true - y_pred))\n","    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n","    return ( 1 - SS_res/(SS_tot + K.epsilon()) ) # K.epsilon()=1E-8 avoids division with zero\n","\n","\n","def build_model(X_train, y_train):\n","    model = Sequential()\n","\n","    n_neurons = int(0.5*X_train.shape[0])\n","    model.add(RBFLayer(n_neurons, centers_initializer=KMeansInit(X_train), input_shape=(5,)))\n","\n","    model.add(Dense(1))\n","\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n","    model.compile(loss = MSE, metrics=[RMSE, R_squared], optimizer=opt)\n","    history = model.fit(X_train, y_train, batch_size=15, epochs=100, verbose=1, validation_split=0.2)\n","\n","    return model, history\n","\n","\n","def plot_curves(history):\n","    # Plot loss\n","\n","    plt.plot(history.history['loss'][2:history.params['epochs']])\n","    plt.plot(history.history['val_loss'][2:history.params['epochs']])\n","    plt.title('Model Loss')\n","    plt.ylabel('MSE')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","\n","def main():\n","    X_train, X_test, y_train, y_test = load_airfoil_dataset()\n","\n","    start_time = time.time()\n","    model, history = build_model(X_train, y_train)\n","    print(f'Training time = {(time.time()-start_time):.2f} seconds.')\n","\n","    start_time = time.time()\n","    model.evaluate(X_test, y_test)\n","    print(f'Testing time = {(time.time()-start_time):.2f} seconds.')\n","\n","    plot_curves(history)\n","    \n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","source":["# 3.RBF ANN With Perceptron Layer"],"metadata":{"id":"IMbUe7o4qrnt"}},{"cell_type":"markdown","source":["##3.1. Fine-tuning RBF+P model using Keras tuner"],"metadata":{"id":"BUx1RuKTqzSF"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras_tuner as kt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from keras import backend as K\n","from tensorflow.keras.layers import Layer\n","from keras.initializers import Initializer, Constant\n","from sklearn.cluster import KMeans\n","\n","\n","def load_airfoil_dataset():\n","    \"\"\"Load the Airfoil Self-Noise dataset from the current directory\n","    \"\"\"\n","    data = pd.read_csv('./airfoil_self_noise.dat', sep='\\t', header=None)\n","\n","    X = data.loc[:, 0:4]\n","    y = data.loc[:, 5]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)\n","\n","    # Feature normalization\n","    mean = X_train.mean(axis=0)\n","    X_train -= mean\n","    X_test -= mean\n","\n","    std = X_train.std(axis=0)\n","    X_train /= std\n","    X_test /= std\n","\n","    return X_train, X_test, y_train, y_test\n","\n","\n","class RBFLayer(Layer):\n","\n","    def __init__(self, output_dim, centers_initializer, betas_trainable=False, **kwargs):\n","        self.output_dim = output_dim  # number of neurons in hidden layer\n","        self.init_betas = np.ones(self.output_dim)\n","        self.betas_trainable = betas_trainable\n","        self.centers_initializer = centers_initializer\n","        super(RBFLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.centers = self.add_weight(name='centers',\n","                                       shape=(self.output_dim, input_shape[1]),\n","                                       initializer=self.centers_initializer,\n","                                       trainable=False)\n","\n","        if self.betas_trainable == True:\n","            self.betas = self.add_weight(name='betas',\n","                                         shape=(self.output_dim,),\n","                                         initializer=Constant(value=self.init_betas),\n","                                         trainable=True)\n","        else:\n","            # find max distance between any two centroids\n","            dmax = 0\n","            for i in range(0, self.output_dim):\n","                for j in range(0, self.output_dim):\n","                    if tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i] - self.centers[j]))) > dmax:\n","                        dmax = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i] - self.centers[j])))\n","\n","            beta = self.output_dim / (dmax ** 2)\n","            self.betas = self.init_betas * beta\n","\n","        super(RBFLayer, self).build(input_shape)\n","\n","    def call(self, x):\n","        C = self.centers[np.newaxis, :, :]\n","        X = x[:, np.newaxis, :]\n","\n","        diffnorm = K.sum((C - X) ** 2, axis=-1)\n","        ret = K.exp(- self.betas * diffnorm)  # this is the RB function\n","        return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_dim)\n","\n","\n","class KMeansInit(Initializer):\n","\n","    def __init__(self, X, max_iter=400):\n","        self.X = X\n","        self.max_iter = max_iter\n","\n","    def __call__(self, shape, dtype=None):\n","        assert shape[1] == self.X.shape[1]\n","\n","        n_centers = shape[0]\n","        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0)\n","        km.fit(self.X)\n","        return km.cluster_centers_\n","\n","\n","def RMSE(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","\n","def MSE(y_true, y_pred):\n","    return K.mean(K.square(y_pred - y_true))\n","\n","\n","def R_squared(y_true, y_pred):\n","    SS_res = K.sum(K.square(y_true - y_pred))\n","    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n","\n","    # Avoid Keras-Tuner selecting NaN value as best\n","    r2_val = 1 - SS_res / (SS_tot + K.epsilon())\n","    if tf.math.is_nan(r2_val):\n","        r2_val = tf.constant(0, dtype=tf.float32)\n","\n","    return r2_val  # K.epsilon()=1E-8 avoids division with zero\n","\n","\n","class myRBFModel(kt.HyperModel):\n","\n","    def __init__(self, X_train):\n","        self.X_train = X_train\n","\n","    def build(self, hp):\n","        model = Sequential()\n","\n","        hp_rbf_neurons = hp.Choice('rbf_neurons',\n","                                   values=[int(0.2 * self.X_train.shape[0]), int(0.3 * self.X_train.shape[0]),\n","                                            int(0.4 * self.X_train.shape[0]), int(0.5 * self.X_train.shape[0]),\n","                                            int(0.6 * self.X_train.shape[0])])\n","        model.add(RBFLayer(hp_rbf_neurons, centers_initializer=KMeansInit(self.X_train), input_shape=(5,)))\n","\n","        hp_perceptron_n = hp.Choice('perceptron_neurons', values=[128, 256, 512])\n","        model.add(Dense(hp_perceptron_n))\n","\n","        model.add(Dense(1))\n","\n","        hp_lr = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001])\n","\n","        hp_opt = hp.Choice('optimizer', values=['adam', 'sgd'])\n","\n","        if hp_opt == 'adam':\n","            with hp.conditional_scope('optimizer', ['adam']):\n","                opt = tf.keras.optimizers.Adam(learning_rate=hp_lr)\n","                model.compile(loss=MSE, metrics=[RMSE, R_squared], optimizer=opt)\n","        else:\n","            with hp.conditional_scope('optimizer', ['sgd']):\n","                opt = tf.keras.optimizers.SGD(learning_rate=hp_lr)\n","                model.compile(loss=MSE, metrics=[RMSE, R_squared], optimizer=opt)\n","\n","        return model\n","\n","\n","def main():\n","    X_train, X_test, y_train, y_test = load_airfoil_dataset()\n","\n","    rbf_model = myRBFModel(X_train=X_train)\n","\n","    # Set up tuner\n","    tuner = kt.RandomSearch(rbf_model, objective=kt.Objective('val_R_squared', direction='max'), max_trials=90,\n","                            executions_per_trial=5, overwrite=True)\n","\n","    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_R_squared', mode='max', patience=100)\n","    nan_stop = tf.keras.callbacks.TerminateOnNaN()\n","    tuner.search(X_train, y_train, epochs=200, validation_split=0.2, batch_size=15, callbacks=[nan_stop, stop_early])\n","\n","    # Get the optimal hyperparameters\n","    best_hps = tuner.get_best_hyperparameters(1)[0]\n","\n","    print(f\"\"\"\n","    The hyperparameter search is complete. The optimal number of neurons for the RBF layer is {best_hps.get('rbf_neurons')}, \n","    for the perceptron layer {best_hps.get('perceptron_neurons')} and the optimal learning rate is {best_hps.get('learning_rate')}.\n","    The optimizer selected is {best_hps.get('optimizer')}.\n","    \"\"\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"mTad5RIIq3ro"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##3.2. Fine-tuned RBF+P model"],"metadata":{"id":"T7JOHg2prCN3"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import time\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from keras import backend as K\n","from tensorflow.keras.layers import Layer\n","from keras.initializers import Initializer, Constant \n","from sklearn.cluster import KMeans\n","\n","\n","def load_airfoil_dataset():\n","    \"\"\"Load the Airfoil Self-Noise dataset from the current directory\n","    \"\"\"\n","    data = pd.read_csv('./airfoil_self_noise.dat', sep='\\t', header=None)\n","\n","    X = data.loc[:,0:4]\n","    y = data.loc[:,5]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)\n","\n","    # Feature normalization\n","    mean = X_train.mean(axis=0)\n","    X_train -= mean\n","    X_test -= mean\n","\n","    std = X_train.std(axis=0)\n","    X_train /= std\n","    X_test /= std\n","\n","    return X_train, X_test, y_train, y_test\n","\n","\n","class RBFLayer(Layer):\n","\n","    def __init__(self, output_dim, centers_initializer, betas_trainable=False, **kwargs):\n","        self.output_dim = output_dim    # number of neurons in hidden layer\n","        self.init_betas = np.ones(self.output_dim)\n","        self.betas_trainable = betas_trainable\n","        self.centers_initializer = centers_initializer\n","        super(RBFLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.centers = self.add_weight(name='centers',\n","                                       shape=(self.output_dim, input_shape[1]),\n","                                       initializer=self.centers_initializer,\n","                                       trainable=False)\n","        \n","        if self.betas_trainable==True:\n","            self.betas = self.add_weight(name='betas',\n","                                        shape=(self.output_dim,),\n","                                        initializer=Constant(value=self.init_betas),\n","                                        trainable=True)\n","        else:\n","            # find max distance between any two centroids\n","            dmax = 0\n","            for i in range(0, self.output_dim):\n","                for j in range(0, self.output_dim):\n","                    if tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i]-self.centers[j]))) > dmax:\n","                        dmax = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.centers[i]-self.centers[j])))\n","            \n","            beta = self.output_dim/(dmax**2)\n","            self.betas = self.init_betas*beta\n","\n","        super(RBFLayer, self).build(input_shape)\n","\n","    def call(self, x):\n","        C = self.centers[np.newaxis, :, :]\n","        X = x[:, np.newaxis, :]\n","\n","        diffnorm = K.sum((C-X)**2, axis=-1)\n","        ret = K.exp( - self.betas * diffnorm)  # this is the RB function\n","        return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_dim)\n","\n","\n","class KMeansInit(Initializer):\n","\n","    def __init__(self, X, max_iter=400):\n","        self.X = X\n","        self.max_iter = max_iter\n","\n","    def __call__(self, shape, dtype=None):\n","        assert shape[1] == self.X.shape[1]\n","\n","        n_centers = shape[0]\n","        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0)\n","        km.fit(self.X)\n","        return km.cluster_centers_\n","\n","\n","def RMSE(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","\n","def MSE(y_true, y_pred):\n","    return K.mean(K.square(y_pred - y_true))\n","\n","\n","def R_squared(y_true, y_pred):\n","    SS_res =  K.sum(K.square(y_true - y_pred))\n","    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n","    return ( 1 - SS_res/(SS_tot + K.epsilon()) ) # K.epsilon()=1E-8 avoids division with zero\n","\n","\n","def build_model(X_train, y_train):\n","    model = Sequential()\n","\n","    n_neurons = int(0.5*X_train.shape[0])\n","    model.add(RBFLayer(n_neurons, centers_initializer=KMeansInit(X_train), input_shape=(5,)))\n","    model.add(Dense(256))\n","    model.add(Dense(1))\n","\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n","    model.compile(loss = MSE, metrics=[RMSE, R_squared], optimizer=opt)\n","    history = model.fit(X_train, y_train, batch_size=15, epochs=100, verbose=1, validation_split=0.2)\n","\n","    return model, history\n","\n","\n","def plot_curves(history):\n","    # Plot loss\n","\n","    plt.plot(history.history['loss'][2:history.params['epochs']])\n","    plt.plot(history.history['val_loss'][2:history.params['epochs']])\n","    plt.title('Model Loss')\n","    plt.ylabel('MSE')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","\n","def main():\n","    X_train, X_test, y_train, y_test = load_airfoil_dataset()\n","\n","    start_time = time.time()\n","    model, history = build_model(X_train, y_train)\n","    print(f'Training time = {(time.time()-start_time):.2f} seconds.')\n","\n","    start_time = time.time()\n","    model.evaluate(X_test, y_test)\n","    print(f'Testing time = {(time.time()-start_time):.2f} seconds.')\n","\n","    plot_curves(history)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"OfZPQt6KrCqw"},"execution_count":null,"outputs":[]}]}