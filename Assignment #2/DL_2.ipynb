{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_2_9352.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOV60B4WWdKrlSLFbsy5quw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **SUPPORT VECTOR MACHINE IMPLEMENTATION**\n","**Dataset:** Statlog Landsat Satelite\n","--\n","\n","***Spyrakis Angelos***, *ECE AUTh (9352)*\n","\n","---\n","Table of Contents:\n","\n","**1. Nearest-Neighbors & Nearest Centroid**\n","\n","**2. Support Vector Machine**\n",">\n",">2.1. Linear SVM\n",">\n",">2.2. Polynomial SVM\n",">\n",">2.3. RBF SVM\n","> \n",">2.4. Implementation with OVO\n","\n","\n","---\n","Execute the following cell to download the dataset."],"metadata":{"id":"nhCiaJXa-ura"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"buCBM9GLvd1s"},"outputs":[],"source":["!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst"]},{"cell_type":"markdown","source":["# 1.Nearest-Neighbors & Nearest Centroid\n","\n"],"metadata":{"id":"AxGLxvAQaatd"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n","\n","\n","def load_landsat():\n","    \"\"\"Load the Landsat Satelite dataset from the current directory\n","    \"\"\"\n","    train = pd.read_csv('./sat.trn', sep=' ', header=None)\n","    test = pd.read_csv('./sat.tst', sep=' ', header=None)\n","\n","    X_train = train.loc[:, 0:35]\n","    y_train = train.loc[:, 36]\n","\n","    X_test = test.loc[:, 0:35]\n","    y_test = test.loc[:, 36]\n","\n","    # Normalize data\n","    X_train, X_test = X_train.astype('float32') / 255.0, X_test.astype('float32') / 255.0\n","\n","    return  X_train, X_test, y_train, y_test\n","\n","\n","def knn(k, X_train, X_test, y_train, y_test):\n","    \"\"\"K-nearest neighbor implementation\n","    \"\"\"\n","    print('Executing KNN with k = %d...\\n' % (k))\n","    start_time = time.time()\n","\n","    knn_classifier = KNeighborsClassifier(n_neighbors=k, weights='uniform', algorithm='auto')\n","    knn_classifier.fit(X_train, y_train)\n","    y_predicted = knn_classifier.predict(X_test)\n","\n","    accuracy = float(np.sum(y_predicted == y_test) / y_test.shape[0])\n","    elapsed_time = time.time() - start_time\n","    print('KNN Accuracy = %f%%' % (accuracy * 100))\n","    print('Elapsed time: %.2f seconds.\\n' % elapsed_time)\n","\n","\n","def nearest_centroid(X_train, X_test, y_train, y_test):\n","    \"\"\"Nearest-Centroid implementation\n","    \"\"\"\n","    print('Executing nearest centroid...\\n')\n","    start_time = time.time()\n","\n","    centroid_classifier = NearestCentroid(metric='euclidean')\n","    centroid_classifier.fit(X_train, y_train)\n","\n","    y_predicted = centroid_classifier.predict(X_test)\n","\n","    accuracy = float(np.sum(y_predicted == y_test) / y_test.shape[0])\n","    elapsed_time = time.time() - start_time\n","    print('Nearest-centroid Accuracy = %f%%' % (accuracy * 100))\n","    print('Elapsed time: %.2f seconds.\\n' % elapsed_time)\n","\n","\n","def main():\n","    \n","    X_train, X_test, y_train, y_test = load_landsat()\n","\n","    #KNN implementation\n","    knn(3, X_train, X_test, y_train, y_test)\n","\n","    #Nearest-Centroid implementation\n","    nearest_centroid(X_train, X_test, y_train, y_test)\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"kXl1Pu0c-iHn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2.Support Vector Machine"],"metadata":{"id":"vPjaeCmALamf"}},{"cell_type":"markdown","source":["## 2.1. Linear SVM"],"metadata":{"id":"qO4Bi3LkODRt"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn import metrics\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","def load_landsat():\n","    \"\"\"Load the Landsat Satelite dataset from the current directory\n","    \"\"\"\n","    train = pd.read_csv('./sat.trn', sep=' ', header=None)\n","    test = pd.read_csv('./sat.tst', sep=' ', header=None)\n","\n","    X_train = train.loc[:, 0:35]\n","    y_train = train.loc[:, 36]\n","\n","    X_test = test.loc[:, 0:35]\n","    y_test = test.loc[:, 36]\n","\n","    # Normalize data\n","    X_train, X_test = X_train.astype('float32') / 255.0, X_test.astype('float32') / 255.0\n","\n","    return  X_train, X_test, y_train, y_test\n","\n","\n","def inter_scores(X_train, y_train, X_test, y_test, C_values, class_w_values):\n","    \"\"\"Calculates intermittent CV and test scores based on C and class_weight values given.\n","    \"\"\"\n","    from sklearn.model_selection import cross_val_score\n","\n","    for C in C_values:\n","        for cw in class_w_values:\n","            print('\\nResults for (C, class_weights) = (', C, ', ', cw, ')')\n","            clf = SVC(kernel='linear', C=C, class_weight=cw, cache_size=500)\n","            scores = cross_val_score(clf, X_train, y_train, cv=5)\n","            print('Mean CV score: %.2f%%' % (scores.mean()*100))\n","            \n","            start_time = time.time()\n","            clf.fit(X_train, y_train)\n","            end_time = time.time()\n","            y_pred = clf.predict(X_test)\n","            print('Training time: %.2f seconds.' % (end_time - start_time))\n","            print('Linear SVM Accuracy = %f%%' % (metrics.accuracy_score(y_test, y_pred)*100))\n","\n","\n","def main():\n","    \"\"\"Linear SVM implementation for the Statlog Landsat dataset.\n","    \"\"\"\n","    X_train, X_test, y_train, y_test = load_landsat()\n","    time_start = time.time()\n","    \n","    # Parameter Range\n","    param_grid = {'C': [0.1, 1, 10, 20, 25, 30, 35, 40, 100, 1000],\n","              'class_weight': ['balanced', None]}\n"," \n","    grid = GridSearchCV(SVC(kernel='linear', cache_size=500), param_grid, refit = True, verbose = 1)\n"," \n","    # Fitting the model for grid search\n","    grid.fit(X_train, y_train)\n","    time_end = time.time()\n","\n","    # Print best parameter after tuning\n","    print('Best parameters after grid-search:')\n","    print(grid.best_params_)\n","    print('\\nGrid-Search time: %.2f seconds.' % (time_end - time_start))\n","    print('Best mean CV score: ', grid.best_score_)\n","\n","    # Predict Xtest and print results\n","    time_start = time.time()\n","    y_pred = grid.predict(X_test)\n","    time_end = time.time()\n","\n","    print('\\nLinear SVM Accuracy = %f%%' % (metrics.accuracy_score(y_test, y_pred)*100))\n","    print('Testing time: %.2f seconds.' % (time_end - time_start))\n","    \n","    # Get intermittent CV scores\n","    \"\"\"\n","    C_values = [0.1, 10, 50, 100, 1000]\n","    class_w_values = [None, 'balanced']\n","    inter_scores(X_train, y_train, X_test, y_test, C_values, class_w_values)\n","    \"\"\"\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"ZyZRa79WOJ-a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2. Polynomial SVM"],"metadata":{"id":"_Hv9R8VJqYLI"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn import metrics\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","def load_landsat():\n","    \"\"\"Load the Landsat Satelite dataset from the current directory\n","    \"\"\"\n","    train = pd.read_csv('./sat.trn', sep=' ', header=None)\n","    test = pd.read_csv('./sat.tst', sep=' ', header=None)\n","\n","    X_train = train.loc[:, 0:35]\n","    y_train = train.loc[:, 36]\n","\n","    X_test = test.loc[:, 0:35]\n","    y_test = test.loc[:, 36]\n","\n","    # Normalize data\n","    X_train, X_test = X_train.astype('float32') / 255.0, X_test.astype('float32') / 255.0\n","\n","    return  X_train, X_test, y_train, y_test\n","\n","\n","def inter_scores(X_train, y_train, X_test, y_test, C_values, degree_values, gamma_values, coef_values):\n","    \"\"\"Calculates intermittent CV and test scores based on C and class_weight values given.\n","    \"\"\"\n","    from sklearn.model_selection import cross_val_score\n","\n","    for C in C_values:\n","        for d in degree_values:\n","            for g in gamma_values:\n","                for coef in coef_values:\n","                    print('\\nResults for (C, degree, gamma, coef0) = (', C, ', ', d, ', ', g, ', ', coef, ')')\n","                    clf = SVC(kernel='poly', C=C, degree=d, cache_size=1000, gamma=g, coef0=coef)\n","                    scores = cross_val_score(clf, X_train, y_train, cv=5)\n","                    print('Mean CV score: %.2f%%' % (scores.mean()*100))\n","\n","                    start_time = time.time()\n","                    clf.fit(X_train, y_train)\n","                    end_time = time.time()\n","                    y_pred = clf.predict(X_test)\n","                    print('Training time: %.2f seconds.' % (end_time - start_time))\n","                    print('Polynomial SVM Accuracy = %.2f%%' % (metrics.accuracy_score(y_test, y_pred)*100))\n","\n","\n","def main():\n","    \"\"\"Polynomial SVM implementation for the Statlog Landsat dataset.\n","    \"\"\"\n","    X_train, X_test, y_train, y_test = load_landsat()\n","    time_start = time.time()\n","    \n","    # Parameter Range\n","    param_grid = {'C': [0.1, 1, 10, 100],\n","              'degree': [1, 2, 3, 4],\n","              'gamma': ['auto', 'scale', 0.1, 1, 10],\n","              'coef0': [0, 1]}\n"," \n","    grid = GridSearchCV(SVC(kernel='poly', cache_size=1000), param_grid, refit = True, verbose = 1)\n"," \n","    # Fitting the model for grid search\n","    grid.fit(X_train, y_train)\n","    time_end = time.time()\n","\n","    # Print best parameter after tuning\n","    print('Best parameters after grid-search:')\n","    print(grid.best_params_)\n","    print('\\nGrid-Search time: %.2f seconds.' % (time_end - time_start))\n","    print('Best mean CV score: ', grid.best_score_)\n","\n","    # Predict Xtest and print results\n","    time_start = time.time()\n","    y_pred = grid.predict(X_test)\n","    time_end = time.time()\n","\n","    print('\\nPolynomial SVM Accuracy = %f%%' % (metrics.accuracy_score(y_test, y_pred)*100))\n","    print('Testing time: %.2f seconds.' % (time_end - time_start))\n","    \n","    # Get intermittent CV scores\n","    \"\"\"\n","    C_values = [0.1, 1]\n","    degree_values = [3, 4, 5, 8]\n","    gamma_values = [1]\n","    coef_values = [1]\n","    class_w_values = [None, 'balanced']\n","    inter_scores(X_train, y_train, X_test, y_test, C_values, degree_values, gamma_values, coef_values)\n","    \"\"\"\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"KTNBrT6Fv7iW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3. RBF SVM"],"metadata":{"id":"MVOj9neuG-gV"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import Normalize\n","from sklearn import metrics\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","def load_landsat():\n","    \"\"\"Load the Landsat Satelite dataset from the current directory\n","    \"\"\"\n","    train = pd.read_csv('./sat.trn', sep=' ', header=None)\n","    test = pd.read_csv('./sat.tst', sep=' ', header=None)\n","\n","    X_train = train.loc[:, 0:35]\n","    y_train = train.loc[:, 36]\n","\n","    X_test = test.loc[:, 0:35]\n","    y_test = test.loc[:, 36]\n","\n","    # Normalize data\n","    X_train, X_test = X_train.astype('float32') / 255.0, X_test.astype('float32') / 255.0\n","\n","    return X_train, X_test, y_train, y_test\n","\n","\n","class MidpointNormalize(Normalize):\n","    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n","        self.midpoint = midpoint\n","        Normalize.__init__(self, vmin, vmax, clip)\n","\n","    def __call__(self, value, clip=None):\n","        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n","        return np.ma.masked_array(np.interp(value, x, y))\n","\n","\n","def inter_scores(X_train, y_train, X_test, y_test, C_values, gamma_values):\n","    \"\"\"Calculates intermittent CV and test scores based on C and class_weight values given.\n","    \"\"\"\n","    from sklearn.model_selection import cross_val_score\n","\n","    for C in C_values:\n","        for g in gamma_values:\n","            print('\\nResults for (C, gamma) = (', C, ', ', g, ')')\n","            clf = SVC(kernel='rbf', C=C, cache_size=1000, gamma=g)\n","            scores = cross_val_score(clf, X_train, y_train, cv=5)\n","            print('Mean CV score: %.2f%%' % (scores.mean() * 100))\n","\n","            start_time = time.time()\n","            clf.fit(X_train, y_train)\n","            end_time = time.time()\n","            y_pred = clf.predict(X_test)\n","            print('Training time: %.2f seconds.' % (end_time - start_time))\n","            print('RBF SVM Accuracy = %.2f%%' % (metrics.accuracy_score(y_test, y_pred) * 100))\n","\n","\n","def plot_heatmap(scores, gamma_values, C_values):\n","    plt.figure(figsize=(8, 6))\n","    plt.subplots_adjust(left=0.2, right=0.95, bottom=0.15, top=0.95)\n","    plt.imshow(\n","        scores,\n","        interpolation=\"nearest\",\n","        cmap=plt.cm.hot,\n","        norm=MidpointNormalize(vmin=0.2, midpoint=0.83),\n","    )\n","    plt.xlabel(\"gamma\")\n","    plt.ylabel(\"C\")\n","    plt.colorbar()\n","    plt.xticks(np.arange(len(gamma_values)), gamma_values, rotation=45)\n","    plt.yticks(np.arange(len(C_values)), C_values)\n","    plt.title(\"Cross-Validation Accuracy\")\n","    plt.show()\n","    \n","\n","def main():\n","    \"\"\"RBF SVM implementation for the Statlog Landsat dataset.\n","    \"\"\"\n","    X_train, X_test, y_train, y_test = load_landsat()\n","    time_start = time.time()\n","\n","    # Parameter Range\n","    C_values = np.logspace(-2, 10, 13)\n","    gamma_values = np.logspace(-9, 3, 13)\n","    param_grid = dict(gamma=gamma_values, C=C_values)\n","\n","    grid = GridSearchCV(SVC(kernel='rbf', cache_size=1000), param_grid, refit=True, verbose=1)\n","\n","    # Fitting the model for grid search\n","    grid.fit(X_train, y_train)\n","    time_end = time.time()\n","\n","    # Print best parameter after tuning\n","    print('Best parameters after grid-search:')\n","    print(grid.best_params_)\n","    print('\\nGrid-Search time: %.2f seconds.' % (time_end - time_start))\n","    print('Best mean CV score: ', grid.best_score_)\n","\n","    # Predict Xtest and print results\n","    time_start = time.time()\n","    y_pred = grid.predict(X_test)\n","    time_end = time.time()\n","\n","    print('\\nRBF SVM Accuracy = %f%%' % (metrics.accuracy_score(y_test, y_pred) * 100))\n","    print('Testing time: %.2f seconds.' % (time_end - time_start))\n","\n","    # Plot CV accuracy heatmap\n","    scores = grid.cv_results_[\"mean_test_score\"].reshape(len(C_values), len(gamma_values))\n","    plot_heatmap(scores, gamma_values, C_values)\n","    \n","    # Get intermittent CV scores\n","    \"\"\"\n","    C_values = [10]\n","    gamma_values = [10]\n","    inter_scores(X_train, y_train, X_test, y_test, C_values, gamma_values)\n","    \"\"\"\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"MVRmjUGhNIoN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.4. Implementation with OVO"],"metadata":{"id":"6wBDiF8L7R8c"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn import metrics\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","def load_landsat():\n","    \"\"\"Load the Landsat Satelite dataset from the current directory\n","    \"\"\"\n","    train = pd.read_csv('./sat.trn', sep=' ', header=None)\n","    test = pd.read_csv('./sat.tst', sep=' ', header=None)\n","\n","    X_train = train.loc[:, 0:35]\n","    y_train = train.loc[:, 36]\n","\n","    X_test = test.loc[:, 0:35]\n","    y_test = test.loc[:, 36]\n","\n","    # Normalize data\n","    X_train, X_test = X_train.astype('float32') / 255.0, X_test.astype('float32') / 255.0\n","\n","    return  X_train, X_test, y_train, y_test\n","\n","\n","def inter_scores(X_train, y_train, X_test, y_test, C_values, degree_values, gamma_values, coef_values):\n","    \"\"\"Calculates intermittent CV and test scores based on C and class_weight values given.\n","    \"\"\"\n","    from sklearn.model_selection import cross_val_score\n","\n","    for C in C_values:\n","        for d in degree_values:\n","            for g in gamma_values:\n","                for coef in coef_values:\n","                    print('\\nResults for (C, degree, gamma, coef0) = (', C, ', ', d, ', ', g, ', ', coef, ')')\n","                    clf = SVC(kernel='poly', C=C, degree=d, cache_size=1000, gamma=g, coef0=coef)\n","                    scores = cross_val_score(clf, X_train, y_train, cv=5)\n","                    print('Mean CV score: %.2f%%' % (scores.mean()*100))\n","\n","                    start_time = time.time()\n","                    clf.fit(X_train, y_train)\n","                    end_time = time.time()\n","                    y_pred = clf.predict(X_test)\n","                    print('Training time: %.2f seconds.' % (end_time - start_time))\n","                    print('Polynomial SVM Accuracy = %.2f%%' % (metrics.accuracy_score(y_test, y_pred)*100))\n","\n","\n","def main():\n","    \"\"\"Polynomial SVM implementation for the Statlog Landsat dataset.\n","    \"\"\"\n","    X_train, X_test, y_train, y_test = load_landsat()\n","    time_start = time.time()\n","    \n","    # Parameter Range\n","    param_grid = {'C': [0.1, 1, 10],\n","              'degree': [3, 4, 5],\n","              'gamma': ['auto', 'scale', 0.1, 1, 10],\n","              'coef0': [0, 1]}\n"," \n","    grid = GridSearchCV(SVC(kernel='poly', decision_function_shape='ovo', cache_size=1000), param_grid, refit = True, verbose = 1)\n"," \n","    # Fitting the model for grid search\n","    grid.fit(X_train, y_train)\n","    time_end = time.time()\n","\n","    # Print best parameter after tuning\n","    print('Best parameters after grid-search:')\n","    print(grid.best_params_)\n","    print('\\nGrid-Search time: %.2f seconds.' % (time_end - time_start))\n","    print('Best mean CV score: ', grid.best_score_)\n","\n","    # Predict Xtest and print results\n","    time_start = time.time()\n","    y_pred = grid.predict(X_test)\n","    time_end = time.time()\n","\n","    print('\\nPolynomial SVM Accuracy = %f%%' % (metrics.accuracy_score(y_test, y_pred)*100))\n","    print('Testing time: %.2f seconds.' % (time_end - time_start))\n","    \n","    # Get intermittent CV scores\n","    \"\"\"\n","    C_values = [0.1, 1]\n","    degree_values = [3, 4, 5, 8]\n","    gamma_values = [1]\n","    coef_values = [1]\n","    class_w_values = [None, 'balanced']\n","    inter_scores(X_train, y_train, X_test, y_test, C_values, degree_values, gamma_values, coef_values)\n","    \"\"\"\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"11Suc6r87SY9"},"execution_count":null,"outputs":[]}]}